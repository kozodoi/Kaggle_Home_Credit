{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas options\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# garbage collection\n",
    "import gc\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR COUNTING MISSINGS\n",
    "def count_missings(data):\n",
    "    total = data.isnull().sum().sort_values(ascending = False)\n",
    "    percent = (data.isnull().sum() / data.isnull().count() * 100).sort_values(ascending = False)\n",
    "    table = pd.concat([total, percent], axis = 1, keys = [\"Total\", \"Percent\"])\n",
    "    table = table[table[\"Total\"] > 0]\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR CONVERTING DATES\n",
    "def convert_days(data, features, t = 12, rounding = True, replace = False):\n",
    "    for var in features:\n",
    "        if replace == True:\n",
    "            if rounding == True:\n",
    "                data[var] = round(-data[var]/t)\n",
    "            else:\n",
    "                data[var] = -data[var]/t\n",
    "            data[var][data[var] < 0] = None\n",
    "        else:\n",
    "            if rounding == True:\n",
    "                data[\"CONVERTED_\" + str(var)] = round(-data[var]/t)\n",
    "            else:\n",
    "                data[\"CONVERTED_\" + str(var)] = -data[var]/t\n",
    "            data[\"CONVERTED_\" + str(var)][data[\"CONVERTED_\" + str(var)] < 0] = None\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR CREATING LOGARITHMS\n",
    "def create_logs(data, features, replace = False):\n",
    "    for var in features:\n",
    "        if replace == True:\n",
    "            data[var] = np.log(data[var].abs() + 1)\n",
    "        else:\n",
    "            data[\"LOG_\" + str(var)] = np.log(data[var].abs() + 1)      \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR CREATING FLAGS FOR MISSINGS\n",
    "def create_null_flags(data, features = None):\n",
    "    if features == None:\n",
    "        features = data.columns\n",
    "    for var in features:\n",
    "        num_null = data[var].isnull() + 0\n",
    "        if num_null.sum() > 0:\n",
    "            data[\"ISNULL_\" + str(var)] = num_null\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR TREATING FACTORS\n",
    "def treat_factors(data, method = \"label\"):\n",
    "    \n",
    "    # label encoding\n",
    "    if method == \"label\":\n",
    "        factors = [f for f in data.columns if data[f].dtype == \"object\"]\n",
    "        for var in factors:\n",
    "            data[var], _ = pd.factorize(data[var])\n",
    "        \n",
    "    # dummy encoding\n",
    "    if method == \"dummy\":\n",
    "        data = pd.get_dummies(data, drop_first = True)\n",
    "    \n",
    "    # dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR COMPUTING ACCEPT/REJECT RATIOS\n",
    "def compute_accept_reject_ratio(data, lags = [1, 3, 5]):\n",
    "    \n",
    "    # preparations\n",
    "    dec_prev = data[[\"SK_ID_CURR\", \"SK_ID_PREV\", \"DAYS_DECISION\", \"NAME_CONTRACT_STATUS\"]]\n",
    "    dec_prev[\"DAYS_DECISION\"] = -dec_prev[\"DAYS_DECISION\"]\n",
    "    dec_prev = dec_prev.sort_values(by = [\"SK_ID_CURR\", \"DAYS_DECISION\"])\n",
    "    dec_prev = pd.get_dummies(dec_prev)\n",
    "     \n",
    "    # compuatation\n",
    "    for t in lags:\n",
    "        \n",
    "        # acceptance ratios\n",
    "        tmp = dec_prev[[\"SK_ID_CURR\", \"NAME_CONTRACT_STATUS_Approved\"]].groupby([\"SK_ID_CURR\"]).head(1)\n",
    "        tmp = tmp.groupby([\"SK_ID_CURR\"], as_index = False).mean()\n",
    "        tmp.columns = [\"SK_ID_CURR\", \"APPROVE_RATIO_\" + str(t)]\n",
    "        data = data.merge(tmp, how = \"left\", on = \"SK_ID_CURR\")\n",
    "        \n",
    "        # rejection ratios\n",
    "        tmp = dec_prev[[\"SK_ID_CURR\", \"NAME_CONTRACT_STATUS_Refused\"]].groupby([\"SK_ID_CURR\"]).head(1)\n",
    "        tmp = tmp.groupby([\"SK_ID_CURR\"], as_index = False).mean()\n",
    "        tmp.columns = [\"SK_ID_CURR\", \"REJECT_RATIO_\" + str(t)]\n",
    "        data = data.merge(tmp, how = \"left\", on = \"SK_ID_CURR\")\n",
    "        \n",
    "    # dataset\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FUNCTION FOR AGGREGATING DATA\n",
    "def aggregate_data(data, id_var, label = None):\n",
    "    \n",
    "    \n",
    "    ### SEPARATE FEATURES\n",
    "  \n",
    "    # display info\n",
    "    print(\"- Preparing the dataset...\")\n",
    "\n",
    "    # find factors\n",
    "    data_factors = [f for f in data.columns if data[f].dtype == \"object\"]\n",
    "    \n",
    "    # partition subsets\n",
    "    num_data = data[list(set(data.columns) - set(data_factors))]\n",
    "    fac_data = data[[id_var] + data_factors]\n",
    "    \n",
    "    # display info\n",
    "    num_facs = fac_data.shape[1] - 1\n",
    "    num_nums = num_data.shape[1] - 1\n",
    "    print(\"- Extracted %.0f factors and %.0f numerics...\" % (num_facs, num_nums))\n",
    "\n",
    "\n",
    "    ##### AGGREGATION\n",
    " \n",
    "    # aggregate numerics\n",
    "    if (num_nums > 0):\n",
    "        print(\"- Aggregating numeric features...\")\n",
    "        num_data = num_data.groupby(id_var).agg([\"mean\", \"std\", \"min\", \"max\"])\n",
    "        num_data.columns = [\"_\".join(col).strip() for col in num_data.columns.values]\n",
    "        num_data = num_data.sort_index()\n",
    "\n",
    "    # aggregate factors\n",
    "    if (num_facs > 0):\n",
    "        print(\"- Aggregating factor features...\")\n",
    "        fac_data = fac_data.groupby(id_var).agg([(\"mode\",   lambda x: scipy.stats.mode(x)[0][0]),\n",
    "                                                 (\"unique\", lambda x: x.nunique())])\n",
    "        fac_data.columns = [\"_\".join(col).strip() for col in fac_data.columns.values]\n",
    "        fac_data = fac_data.sort_index()\n",
    "\n",
    "\n",
    "    ##### MERGER\n",
    "\n",
    "    # merge numerics and factors\n",
    "    if ((num_facs > 0) & (num_nums > 0)):\n",
    "        agg_data = pd.concat([num_data, fac_data], axis = 1)\n",
    "    \n",
    "    # use factors only\n",
    "    if ((num_facs > 0) & (num_nums == 0)):\n",
    "        agg_data = fac_data\n",
    "        \n",
    "    # use numerics only\n",
    "    if ((num_facs == 0) & (num_nums > 0)):\n",
    "        agg_data = num_data\n",
    "        \n",
    "\n",
    "    ##### LAST STEPS\n",
    "\n",
    "    # update labels\n",
    "    if label != None:\n",
    "        agg_data.columns = [label + \"_\" + str(col) for col in agg_data.columns]\n",
    "    \n",
    "    # impute zeros for SD\n",
    "    #stdevs = agg_data.filter(like = \"_std\").columns\n",
    "    #for var in stdevs:\n",
    "    #    agg_data[var].fillna(0, inplace = True)\n",
    "\n",
    "    # display info\n",
    "    print(\"- Final dimensions:\", agg_data.shape)\n",
    "    \n",
    "    # return dataset\n",
    "    return agg_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train = pd.read_csv(\"../data/raw/application_train.csv\")\n",
    "test  = pd.read_csv(\"../data/raw/application_test.csv\")\n",
    "buro  = pd.read_csv(\"../data/raw/bureau.csv\")\n",
    "bbal  = pd.read_csv(\"../data/raw/bureau_balance.csv\")\n",
    "prev  = pd.read_csv(\"../data/raw/previous_application.csv\")\n",
    "card  = pd.read_csv(\"../data/raw/credit_card_balance.csv\")\n",
    "poca  = pd.read_csv(\"../data/raw/POS_CASH_balance.csv\")\n",
    "inst  = pd.read_csv(\"../data/raw/installments_payments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "print(\"Application:\", train.shape, test.shape)\n",
    "print(\"Buro:\", buro.shape)\n",
    "print(\"Bbal:\", bbal.shape)\n",
    "print(\"Prev:\", prev.shape)\n",
    "print(\"Card:\", card.shape)\n",
    "print(\"Poca:\", poca.shape)\n",
    "print(\"Inst:\", inst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract target\n",
    "y = train[[\"SK_ID_CURR\", \"TARGET\"]]\n",
    "del train[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. APPLICATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate application data\n",
    "appl = pd.concat([train, test])\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# income ratios\n",
    "appl[\"CREDIT_BY_INCOME\"]      = appl[\"AMT_CREDIT\"]      / appl[\"AMT_INCOME_TOTAL\"]\n",
    "appl[\"ANNUITY_BY_INCOME\"]     = appl[\"AMT_ANNUITY\"]     / appl[\"AMT_INCOME_TOTAL\"]\n",
    "appl[\"GOODS_PRICE_BY_INCOME\"] = appl[\"AMT_GOODS_PRICE\"] / appl[\"AMT_INCOME_TOTAL\"]\n",
    "appl[\"INCOME_PER_PERSON\"]     = appl[\"AMT_INCOME_TOTAL\"] / appl[\"CNT_FAM_MEMBERS\"]\n",
    "\n",
    "# career ratio\n",
    "appl[\"PERCENT_WORKED\"] = appl[\"DAYS_EMPLOYED\"] / appl[\"DAYS_BIRTH\"]\n",
    "appl[\"PERCENT_WORKED\"][appl[\"PERCENT_WORKED\"] < 0] = None\n",
    "\n",
    "# number of adults\n",
    "appl[\"CNT_ADULTS\"] = appl[\"CNT_FAM_MEMBERS\"] - appl[\"CNT_CHILDREN\"]\n",
    "appl['CHILDREN_RATIO'] = appl['CNT_CHILDREN'] / appl['CNT_FAM_MEMBERS']\n",
    "\n",
    "# number of overall payments\n",
    "appl['ANNUITY LENGTH'] = appl['AMT_CREDIT'] / appl['AMT_ANNUITY']\n",
    "\n",
    "# external sources\n",
    "#appl[\"EXT_SOURCE_MIN\"]  = appl[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].min(axis = 1)\n",
    "#appl[\"EXT_SOURCE_MAX\"]  = appl[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].max(axis = 1)\n",
    "appl[\"EXT_SOURCE_MEAN\"] = appl[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(axis = 1)\n",
    "#appl[\"EXT_SOURCE_SD\"]   = appl[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].std(axis = 1)\n",
    "appl[\"NUM_EXT_SOURCES\"] = 3 - (appl[\"EXT_SOURCE_1\"].isnull().astype(int) +\n",
    "                               appl[\"EXT_SOURCE_2\"].isnull().astype(int) +\n",
    "                               appl[\"EXT_SOURCE_3\"].isnull().astype(int))\n",
    "\n",
    "# number of documents\n",
    "doc_vars = [\"FLAG_DOCUMENT_2\",  \"FLAG_DOCUMENT_3\",  \"FLAG_DOCUMENT_4\",  \"FLAG_DOCUMENT_5\",  \"FLAG_DOCUMENT_6\",\n",
    "            \"FLAG_DOCUMENT_7\",  \"FLAG_DOCUMENT_8\",  \"FLAG_DOCUMENT_9\",  \"FLAG_DOCUMENT_10\", \"FLAG_DOCUMENT_11\",\n",
    "            \"FLAG_DOCUMENT_12\", \"FLAG_DOCUMENT_13\", \"FLAG_DOCUMENT_14\", \"FLAG_DOCUMENT_15\", \"FLAG_DOCUMENT_16\",\n",
    "            \"FLAG_DOCUMENT_17\", \"FLAG_DOCUMENT_18\", \"FLAG_DOCUMENT_19\", \"FLAG_DOCUMENT_20\", \"FLAG_DOCUMENT_21\"]\n",
    "appl[\"NUM_DOCUMENTS\"] = appl[doc_vars].sum(axis = 1)\n",
    "\n",
    "# application date\n",
    "appl[\"DAY_APPR_PROCESS_START\"] = \"Working day\"\n",
    "appl[\"DAY_APPR_PROCESS_START\"][(appl[\"WEEKDAY_APPR_PROCESS_START\"] == \"SATURDAY\") |\n",
    "                               (appl[\"WEEKDAY_APPR_PROCESS_START\"] == \"SUNDAY\")] = \"Weekend\"\n",
    "\n",
    "# logarithms\n",
    "log_vars = [\"AMT_CREDIT\", \"AMT_INCOME_TOTAL\", \"AMT_GOODS_PRICE\", \"AMT_ANNUITY\"]\n",
    "appl = create_logs(appl, log_vars, replace = True)\n",
    "\n",
    "# convert days\n",
    "day_vars = [\"DAYS_BIRTH\", \"DAYS_REGISTRATION\", \"DAYS_ID_PUBLISH\", \"DAYS_EMPLOYED\", \"DAYS_LAST_PHONE_CHANGE\"]\n",
    "appl = convert_days(appl, day_vars, t = 30, rounding = True, replace = True)\n",
    "\n",
    "# age ratios\n",
    "appl[\"OWN_CAR_AGE_RATIO\"] = appl[\"OWN_CAR_AGE\"] / appl[\"DAYS_BIRTH\"]\n",
    "appl[\"DAYS_ID_PUBLISHED_RATIO\"] = appl[\"DAYS_ID_PUBLISH\"] / appl[\"DAYS_BIRTH\"]\n",
    "appl[\"DAYS_REGISTRATION_RATIO\"] = appl[\"DAYS_REGISTRATION\"] / appl[\"DAYS_BIRTH\"]\n",
    "appl[\"DAYS_LAST_PHONE_CHANGE_RATIO\"] = appl[\"DAYS_LAST_PHONE_CHANGE\"] / appl[\"DAYS_BIRTH\"]\n",
    "\n",
    "\n",
    "##### FEATURE REMOVAL\n",
    "drops = ['APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', \n",
    "         'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI',\n",
    "         'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI','YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI',\n",
    "         'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'COMMONAREA_MODE','ELEVATORS_MODE', 'ENTRANCES_MODE', \n",
    "         'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', \n",
    "         'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'TOTALAREA_MODE',  'YEARS_BEGINEXPLUATATION_MODE']\n",
    "appl = appl.drop(columns = drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename features\n",
    "appl.columns = [\"SK_ID_CURR\"] + [\"app_\" + str(col) for col in appl.columns if col not in \"SK_ID_CURR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "appl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(appl)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. CREDIT BUREAU DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. BBAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check bbal data\n",
    "bbal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# loan default score\n",
    "bbal[\"NUM_STATUS\"] = 0\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"X\"] = None\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"1\"] = 1\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"2\"] = 2\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"3\"] = 3\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"4\"] = 4\n",
    "bbal[\"NUM_STATUS\"][bbal[\"STATUS\"] == \"5\"] = 5\n",
    "bbal[\"LOAN_SCORE\"] = bbal[\"NUM_STATUS\"] / (abs(bbal[\"MONTHS_BALANCE\"]) + 1)\n",
    "loan_score = bbal.groupby(\"SK_ID_BUREAU\", as_index = False).LOAN_SCORE.sum()\n",
    "del bbal[\"NUM_STATUS\"]\n",
    "del bbal[\"LOAN_SCORE\"]\n",
    "\n",
    "# dummy encoding for STATUS\n",
    "bbal = pd.get_dummies(bbal, columns = [\"STATUS\"], prefix = \"STATUS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(bbal)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# total month count\n",
    "cnt_mon = bbal[[\"SK_ID_BUREAU\", \"MONTHS_BALANCE\"]].groupby(\"SK_ID_BUREAU\").count()\n",
    "del bbal[\"MONTHS_BALANCE\"]\n",
    "\n",
    "# aggregate data\n",
    "agg_bbal = bbal.groupby(\"SK_ID_BUREAU\").mean()\n",
    "\n",
    "# add total month count\n",
    "agg_bbal[\"MONTH_COUNT\"] = cnt_mon\n",
    "\n",
    "# add loan score\n",
    "agg_bbal = agg_bbal.merge(loan_score, how = \"left\", on = \"SK_ID_BUREAU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_bbal)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_bbal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del bbal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. BURO DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check buro data\n",
    "buro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MERGE\n",
    "buro = buro.merge(right = agg_bbal.reset_index(), how = \"left\", on = \"SK_ID_BUREAU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### FEATURE ENGINEERING\n",
    "\n",
    "# number of buro loans \n",
    "cnt_buro = buro[[\"SK_ID_CURR\", \"SK_ID_BUREAU\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "cnt_buro.columns = [\"SK_ID_CURR\", \"CNT_BURO_LOANS\"]\n",
    "buro = buro.merge(cnt_buro, how = \"left\", on = \"SK_ID_CURR\")\n",
    "\n",
    "# amount ratios\n",
    "buro[\"AMT_SUM_OVERDUE_RATIO_1\"] = buro[\"AMT_CREDIT_SUM_OVERDUE\"] / buro[\"AMT_ANNUITY\"]\n",
    "buro[\"AMT_SUM_OVERDUE_RATIO_2\"] = buro[\"AMT_CREDIT_SUM_OVERDUE\"] / buro[\"AMT_CREDIT_SUM\"]\n",
    "buro[\"AMT_MAX_OVERDUE_RATIO_1\"] = buro[\"AMT_CREDIT_MAX_OVERDUE\"] / buro[\"AMT_ANNUITY\"]\n",
    "buro[\"AMT_MAX_OVERDUE_RATIO_2\"] = buro[\"AMT_CREDIT_MAX_OVERDUE\"] / buro[\"AMT_CREDIT_SUM\"]\n",
    "buro[\"AMT_SUM_DEBT_RATIO_1\"]    = buro[\"AMT_CREDIT_SUM_DEBT\"] / buro[\"AMT_CREDIT_SUM\"]\n",
    "buro[\"AMT_SUM_DEBT_RATIO_2\"]    = buro[\"AMT_CREDIT_SUM_DEBT\"] / buro[\"AMT_CREDIT_SUM_LIMIT\"]\n",
    "\n",
    "# logarithms\n",
    "log_vars = [\"AMT_CREDIT_SUM\", \"AMT_CREDIT_SUM_DEBT\", \"AMT_CREDIT_SUM_LIMIT\", \"AMT_CREDIT_SUM_OVERDUE\", \"AMT_ANNUITY\"]\n",
    "buro = create_logs(buro, log_vars, replace = True)\n",
    "\n",
    "# convert days\n",
    "day_vars = [\"DAYS_CREDIT\", \"CREDIT_DAY_OVERDUE\", \"DAYS_CREDIT_ENDDATE\", \"DAYS_ENDDATE_FACT\", \"DAYS_CREDIT_UPDATE\"]\n",
    "buro = convert_days(buro, day_vars, t = 1, rounding = False, replace = True)\n",
    "\n",
    "# recency-weighted loan score\n",
    "buro[\"WEIGHTED_LOAN_SCORE\"] = buro[\"LOAN_SCORE\"] / (buro[\"DAYS_CREDIT\"] / 12)\n",
    "\n",
    "# day differences\n",
    "buro[\"DAYS_END_DIFF_1\"] = buro[\"DAYS_ENDDATE_FACT\"]   - buro[\"DAYS_CREDIT_ENDDATE\"]\n",
    "buro[\"DAYS_END_DIFF_2\"] = buro[\"DAYS_CREDIT_UPDATE\"]  - buro[\"DAYS_CREDIT_ENDDATE\"]\n",
    "buro[\"DAYS_DURATION_1\"] = buro[\"DAYS_CREDIT_ENDDATE\"] - buro[\"DAYS_CREDIT\"]\n",
    "buro[\"DAYS_DURATION_2\"] = buro[\"DAYS_ENDDATE_FACT\"]   - buro[\"DAYS_CREDIT\"]\n",
    "\n",
    "# number of active buro loans\n",
    "cnt_buro = buro[[\"SK_ID_CURR\", \"CREDIT_ACTIVE\"]]\n",
    "cnt_buro.columns = [\"SK_ID_CURR\", \"CNT_BURO_ACTIVE\"]\n",
    "cnt_buro = cnt_buro[cnt_buro[\"CNT_BURO_ACTIVE\"] == \"Active\"]\n",
    "cnt_buro = cnt_buro[[\"SK_ID_CURR\", \"CNT_BURO_ACTIVE\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "buro = buro.merge(cnt_buro, how = \"left\", on = \"SK_ID_CURR\")\n",
    "buro[\"CNT_BURO_ACTIVE\"].fillna(0, inplace = True)\n",
    "\n",
    "# number of closed buro loans\n",
    "cnt_buro = buro[[\"SK_ID_CURR\", \"CREDIT_ACTIVE\"]]\n",
    "cnt_buro.columns = [\"SK_ID_CURR\", \"CNT_BURO_CLOSED\"]\n",
    "cnt_buro = cnt_buro[cnt_buro[\"CNT_BURO_CLOSED\"] == \"Closed\"]\n",
    "cnt_buro = cnt_buro[[\"SK_ID_CURR\", \"CNT_BURO_CLOSED\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "buro = buro.merge(cnt_buro, how = \"left\", on = \"SK_ID_CURR\")\n",
    "buro[\"CNT_BURO_CLOSED\"].fillna(0, inplace = True)\n",
    "\n",
    "# number of defaulted buro loans\n",
    "cnt_buro = buro[[\"SK_ID_CURR\", \"CREDIT_ACTIVE\"]]\n",
    "cnt_buro.columns = [\"SK_ID_CURR\", \"CNT_BURO_BAD\"]\n",
    "cnt_buro = cnt_buro[cnt_buro[\"CNT_BURO_BAD\"] == \"Bad debt\"]\n",
    "cnt_buro = cnt_buro[[\"SK_ID_CURR\", \"CNT_BURO_BAD\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "buro = buro.merge(cnt_buro, how = \"left\", on = \"SK_ID_CURR\")\n",
    "buro[\"CNT_BURO_BAD\"].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "buro = pd.get_dummies(buro, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(buro)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# count previous buro loans\n",
    "cnt_buro = buro[[\"SK_ID_CURR\", \"SK_ID_BUREAU\"]].groupby(\"SK_ID_CURR\").count()\n",
    "del buro[\"SK_ID_BUREAU\"]\n",
    "\n",
    "# aggregate data\n",
    "agg_buro = aggregate_data(buro, id_var = \"SK_ID_CURR\", label = \"buro\")\n",
    "\n",
    "# add buro loan count\n",
    "agg_buro[\"buro_BURO_COUNT\"] = cnt_buro\n",
    "\n",
    "# clean up\n",
    "omits = [\"WEIGHTED_LOAN_SCORE\"]\n",
    "for var in omits:\n",
    "    del agg_buro[\"buro_\" + str(var) + \"_std\"]\n",
    "    del agg_buro[\"buro_\" + str(var) + \"_min\"]\n",
    "    del agg_buro[\"buro_\" + str(var) + \"_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_buro)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_buro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del buro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. PREVIOUS LOAN DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. INST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check inst data\n",
    "inst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# days past due and days before due (no negative values)\n",
    "inst['DPD'] = inst['DAYS_ENTRY_PAYMENT'] - inst['DAYS_INSTALMENT']\n",
    "inst['DBD'] = inst['DAYS_INSTALMENT'] - inst['DAYS_ENTRY_PAYMENT']\n",
    "inst['DPD'] = inst['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "inst['DBD'] = inst['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "# percentage and difference paid in each installment \n",
    "inst['PAYMENT_PERC'] = inst['AMT_PAYMENT'] / inst['AMT_INSTALMENT']\n",
    "inst['PAYMENT_DIFF'] = inst['AMT_INSTALMENT'] - inst['AMT_PAYMENT']\n",
    "\n",
    "# logarithms\n",
    "log_vars = [\"AMT_INSTALMENT\", \"AMT_PAYMENT\"]\n",
    "inst = create_logs(inst, log_vars, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "inst = pd.get_dummies(inst, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(inst)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# count instalments\n",
    "cnt_inst = inst[[\"SK_ID_PREV\", \"NUM_INSTALMENT_NUMBER\"]].groupby(\"SK_ID_PREV\").count()\n",
    "del inst[\"NUM_INSTALMENT_NUMBER\"]\n",
    "\n",
    "# delete ID_CURR\n",
    "inst_id = inst[[\"SK_ID_CURR\", \"SK_ID_PREV\"]]\n",
    "del inst[\"SK_ID_CURR\"]\n",
    "\n",
    "# aggregate data\n",
    "agg_inst = aggregate_data(inst, id_var = \"SK_ID_PREV\")\n",
    "\n",
    "# add instalment count\n",
    "agg_inst[\"inst_INST_COUNT\"] = cnt_inst\n",
    "\n",
    "# put back ID_CURR\n",
    "inst_id = inst_id.drop_duplicates()\n",
    "agg_inst = inst_id.merge(right = agg_inst.reset_index(), how = \"right\", on = \"SK_ID_PREV\")\n",
    "del agg_inst[\"SK_ID_PREV\"]\n",
    "\n",
    "# aggregate data (round 2)\n",
    "agg_inst = aggregate_data(agg_inst, id_var = \"SK_ID_CURR\", label = \"inst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_inst)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_inst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del inst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2. POCA DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check poca data\n",
    "poca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# installments percentage\n",
    "poca[\"INSTALLMENTS_PERCENT\"] = poca[\"CNT_INSTALMENT_FUTURE\"] / poca[\"CNT_INSTALMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "poca = pd.get_dummies(poca, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(poca)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# count months\n",
    "cnt_mon = poca[[\"SK_ID_PREV\", \"MONTHS_BALANCE\"]].groupby(\"SK_ID_PREV\").count()\n",
    "del poca[\"MONTHS_BALANCE\"]\n",
    "\n",
    "# delete ID_CURR\n",
    "poca_id = poca[[\"SK_ID_CURR\", \"SK_ID_PREV\"]]\n",
    "del poca[\"SK_ID_CURR\"]\n",
    "\n",
    "# aggregate data\n",
    "agg_poca = aggregate_data(poca, id_var = \"SK_ID_PREV\")\n",
    "\n",
    "# add month count\n",
    "agg_poca[\"poca_MON_COUNT\"] = cnt_mon\n",
    "\n",
    "# put back ID_CURR\n",
    "poca_id = poca_id.drop_duplicates()\n",
    "agg_poca = poca_id.merge(right = agg_poca.reset_index(), how = \"right\", on = \"SK_ID_PREV\")\n",
    "del agg_poca[\"SK_ID_PREV\"]\n",
    "\n",
    "# aggregate data (round 2)\n",
    "agg_poca = aggregate_data(agg_poca, id_var = \"SK_ID_CURR\", label = \"poca\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_poca)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_poca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del poca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. CARD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check card data\n",
    "card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# logarithms\n",
    "log_vars = [\"AMT_BALANCE\", \"AMT_CREDIT_LIMIT_ACTUAL\", \"AMT_DRAWINGS_ATM_CURRENT\", \"AMT_DRAWINGS_CURRENT\",\n",
    "            \"AMT_DRAWINGS_OTHER_CURRENT\", \"AMT_DRAWINGS_POS_CURRENT\", \"AMT_INST_MIN_REGULARITY\",\n",
    "            \"AMT_PAYMENT_CURRENT\", \"AMT_PAYMENT_TOTAL_CURRENT\", \"AMT_RECEIVABLE_PRINCIPAL\",\n",
    "            \"AMT_RECIVABLE\", \"AMT_TOTAL_RECEIVABLE\"]\n",
    "card = create_logs(card, log_vars, replace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "card = pd.get_dummies(card, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(card)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# count months\n",
    "cnt_mon = card[[\"SK_ID_PREV\", \"MONTHS_BALANCE\"]].groupby(\"SK_ID_PREV\").count()\n",
    "del card[\"MONTHS_BALANCE\"]\n",
    "\n",
    "# delete ID_CURR\n",
    "card_id = card[[\"SK_ID_CURR\", \"SK_ID_PREV\"]]\n",
    "del card[\"SK_ID_CURR\"]\n",
    "\n",
    "# aggregate data\n",
    "agg_card = aggregate_data(card, id_var = \"SK_ID_PREV\")\n",
    "\n",
    "# add month count\n",
    "agg_card[\"card_MON_COUNT\"] = cnt_mon\n",
    "\n",
    "# put back ID_CURR\n",
    "card_id = card_id.drop_duplicates()\n",
    "agg_card = card_id.merge(right = agg_card.reset_index(), how = \"right\", on = \"SK_ID_PREV\")\n",
    "del agg_card[\"SK_ID_PREV\"]\n",
    "\n",
    "# aggregate data (round 2)\n",
    "agg_card = aggregate_data(agg_card, id_var = \"SK_ID_CURR\", label = \"card\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_card)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_card.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del card"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4. PREV DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check card data\n",
    "prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FEATURE ENGINEERING\n",
    "\n",
    "# amount ratios\n",
    "prev[\"AMT_GIVEN_RATIO_1\"]  = prev[\"AMT_CREDIT\"] / prev[\"AMT_APPLICATION\"]\n",
    "prev[\"AMT_GIVEN_RATIO_2\"]  = prev[\"AMT_GOODS_PRICE\"] / prev[\"AMT_APPLICATION\"]\n",
    "prev[\"DOWN_PAYMENT_RATIO\"] = prev[\"AMT_DOWN_PAYMENT\"] / prev[\"AMT_APPLICATION\"]\n",
    "\n",
    "# logarithms\n",
    "log_vars = [\"AMT_CREDIT\", \"AMT_ANNUITY\", \"AMT_APPLICATION\", \"AMT_DOWN_PAYMENT\", \"AMT_GOODS_PRICE\"]\n",
    "prev = create_logs(prev, log_vars, replace = True)\n",
    "\n",
    "# convert days\n",
    "day_vars = [\"DAYS_FIRST_DRAWING\", \"DAYS_FIRST_DUE\", \"DAYS_LAST_DUE_1ST_VERSION\", \n",
    "            \"DAYS_LAST_DUE\", \"DAYS_TERMINATION\", \"DAYS_DECISION\"]\n",
    "prev = convert_days(prev, day_vars, t = 1, rounding = False, replace = True)\n",
    "\n",
    "# number of applications \n",
    "cnt_prev = prev[[\"SK_ID_CURR\", \"SK_ID_PREV\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "cnt_prev.columns = [\"SK_ID_CURR\", \"CNT_PREV_APPLICATIONS\"]\n",
    "prev = prev.merge(cnt_prev, how = \"left\", on = \"SK_ID_CURR\")\n",
    "\n",
    "# number of contracts\n",
    "cnt_prev = prev[[\"SK_ID_CURR\", \"FLAG_LAST_APPL_PER_CONTRACT\"]]\n",
    "cnt_prev.columns = [\"SK_ID_CURR\", \"CNT_PREV_CONTRACTS\"]\n",
    "cnt_prev = cnt_prev[cnt_prev[\"CNT_PREV_CONTRACTS\"] == \"Y\"]\n",
    "cnt_prev = cnt_prev[[\"SK_ID_CURR\", \"CNT_PREV_CONTRACTS\"]].groupby([\"SK_ID_CURR\"], as_index = False).count()\n",
    "prev = prev.merge(cnt_prev, how = \"left\", on = \"SK_ID_CURR\")\n",
    "\n",
    "# number ratio\n",
    "prev[\"APPL_PER_CONTRACT_RATIO\"] = prev[\"CNT_PREV_APPLICATIONS\"] / prev[\"CNT_PREV_CONTRACTS\"]\n",
    "\n",
    "# loan decision ratios\n",
    "prev = compute_accept_reject_ratio(prev, lags = [1, 3, 5])\n",
    "\n",
    "# day differences\n",
    "prev[\"DAYS_DUE_DIFF_1\"] = prev[\"DAYS_LAST_DUE_1ST_VERSION\"] - prev[\"DAYS_FIRST_DUE\"]\n",
    "prev[\"DAYS_DUE_DIFF_2\"] = prev[\"DAYS_LAST_DUE\"] - prev[\"DAYS_FIRST_DUE\"]\n",
    "prev[\"DAYS_TERMINATION_DIFF_1\"] = prev[\"DAYS_TERMINATION\"] - prev[\"DAYS_FIRST_DRAWING\"]\n",
    "prev[\"DAYS_TERMINATION_DIFF_2\"] = prev[\"DAYS_TERMINATION\"] - prev[\"DAYS_FIRST_DUE\"]\n",
    "prev[\"DAYS_TERMINATION_DIFF_3\"] = prev[\"DAYS_TERMINATION\"] - prev[\"DAYS_LAST_DUE\"]\n",
    "\n",
    "# application dates\n",
    "prev[\"DAY_APPR_PROCESS_START\"] = \"Working day\"\n",
    "prev[\"DAY_APPR_PROCESS_START\"][(prev[\"WEEKDAY_APPR_PROCESS_START\"] == \"SATURDAY\") |\n",
    "                               (prev[\"WEEKDAY_APPR_PROCESS_START\"] == \"SUNDAY\")] = \"Weekend\"\n",
    "\n",
    "\n",
    "##### FEATURE REMOVAL\n",
    "drops = [\"NAME_CLIENT_TYPE\", \"SK_ID_PREV\"]\n",
    "prev = prev.drop(columns = drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "prev = pd.get_dummies(prev, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(prev)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### AGGREGATIONS\n",
    "\n",
    "# aggregate data\n",
    "agg_prev = aggregate_data(prev, id_var = \"SK_ID_CURR\", label = \"prev\")\n",
    "\n",
    "# clean up\n",
    "omits = [\"APPROVE_RATIO_1\", \"APPROVE_RATIO_3\", \"APPROVE_RATIO_5\",  \n",
    "         \"REJECT_RATIO_1\", \"REJECT_RATIO_3\",  \"REJECT_RATIO_5\", \n",
    "         \"FLAG_LAST_APPL_PER_CONTRACT_Y\", \"CNT_PREV_CONTRACTS\", \"CNT_PREV_APPLICATIONS\", \n",
    "         \"APPL_PER_CONTRACT_RATIO\"]\n",
    "for var in omits:\n",
    "    del agg_prev[\"prev_\" + str(var) + \"_std\"]\n",
    "    del agg_prev[\"prev_\" + str(var) + \"_min\"]\n",
    "    del agg_prev[\"prev_\" + str(var) + \"_max\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(agg_prev)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data\n",
    "agg_prev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear memory\n",
    "del prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATA EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "print(appl.shape)\n",
    "appl = appl.merge(right = agg_buro.reset_index(), how = \"left\", on = \"SK_ID_CURR\")\n",
    "print(appl.shape)\n",
    "del agg_buro\n",
    "appl = appl.merge(right = agg_prev.reset_index(), how = \"left\", on = \"SK_ID_CURR\")\n",
    "print(appl.shape)\n",
    "del agg_prev\n",
    "appl = appl.merge(right = agg_inst.reset_index(), how = \"left\", on = \"SK_ID_CURR\")\n",
    "print(appl.shape)\n",
    "del agg_inst\n",
    "appl = appl.merge(right = agg_poca.reset_index(), how = \"left\", on = \"SK_ID_CURR\")\n",
    "print(appl.shape)\n",
    "del agg_poca\n",
    "appl = appl.merge(right = agg_card.reset_index(), how = \"left\", on = \"SK_ID_CURR\")\n",
    "print(appl.shape)\n",
    "del agg_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CROSS-TABLE FEATURE ENGINEERING\n",
    "\n",
    "# credit ratios\n",
    "appl[\"mix_AMT_PREV_ANNUITY_RATIO\"]     = appl[\"app_AMT_ANNUITY\"] / appl[\"prev_AMT_ANNUITY_mean\"]\n",
    "appl[\"mix_AMT_PREV_CREDIT_RATIO\"]      = appl[\"app_AMT_CREDIT\"] / appl[\"prev_AMT_CREDIT_mean\"]\n",
    "appl[\"mix_AMT_PREV_GOODS_PRICE_RATIO\"] = appl[\"app_AMT_GOODS_PRICE\"] / appl[\"prev_AMT_GOODS_PRICE_mean\"]\n",
    "appl[\"mix_AMT_BURO_ANNUITY_RATIO\"]     = appl[\"app_AMT_ANNUITY\"] / appl[\"buro_AMT_ANNUITY_mean\"]\n",
    "appl[\"mix_AMT_BURO_CREDIT_RATIO\"]      = appl[\"app_AMT_CREDIT\"] / appl[\"buro_AMT_CREDIT_SUM_mean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy encodnig for factors\n",
    "appl = pd.get_dummies(appl, drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoder for factors\n",
    "#data_factors = [f for f in appl.columns if appl[f].dtype == \"object\"]\n",
    "#for var in data_factors:\n",
    "#    appl[var], _ = pd.factorize(appl[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count missings\n",
    "nas = count_missings(appl)\n",
    "nas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partitioning\n",
    "train = appl[appl[\"SK_ID_CURR\"].isin(y[\"SK_ID_CURR\"]) == True]\n",
    "test  = appl[appl[\"SK_ID_CURR\"].isin(y[\"SK_ID_CURR\"]) == False]\n",
    "del appl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dimensions\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export CSV\n",
    "train.to_csv(\"../data/prepared/train_full_cor.csv\", index = False, float_format = \"%.8f\")\n",
    "test.to_csv(\"../data/prepared/test_full_cor.csv\",   index = False, float_format = \"%.8f\")\n",
    "y.to_csv(\"../data/prepared/y_full_cor.csv\",         index = False, float_format = \"%.8f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
